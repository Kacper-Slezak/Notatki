---
typ: projekt
status: " w-produkcji"
technologie:
  - Kubernetes
  - FastAPI
  - Prometheus
  - Redis
  - PostgreSQL
priorytet: "7"
data_aktualizacji: 2025-12-20
---

# üõ∞Ô∏è System Observability & Telemetry Platform (SOTP)

> [!abstract] Cel Projektu
> Budowa kompleksowej platformy monitoringu infrastruktury sieciowej z wykorzystaniem stosu PLT i GitOps.

### Streszczenie ZarzƒÖdcze

SOTP to flagowa platforma do monitoringu infrastruktury sieciowej, ≈ÇƒÖczƒÖca:

- NowoczesnƒÖ architekturƒô (Kubernetes, GitOps, Service Mesh)
    
- Pe≈ÇnƒÖ obserwowalno≈õƒá (Metryki, Logi, ≈ölady - Stos PLT)
    
- Bezpiecze≈Ñstwo klasy enterprise (Vault, mTLS, RBAC)
    
- Automatyzacjƒô (Automatyczna naprawa, predykcje AI/ML)
    

Kluczowe cechy:

- Natywny dla Kubernetes (K3d lokalnie, gotowy na chmurƒô)
    
- Wdro≈ºenia GitOps (ArgoCD)
    
- Pe≈Çny stos obserwowalno≈õci (Prometheus + Loki + Tempo)
    
- Bezpiecze≈Ñstwo Zero-Trust (Service Mesh + Vault)
    
- Inteligentna automatyzacja (Predykcje ML, auto-remediacja)
    

### Architektura

#### Warstwa Logiczna (Architektura Aplikacji)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 WARSTWA INTERFEJSU U≈ªYTKOWNIKA              ‚îÇ
‚îÇ  Next.js 14 (React) + Tailwind CSS + shadcn/ui              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTPS (Traefik Ingress)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   WARSTWA BRAMY API                         ‚îÇ
‚îÇ  Traefik (Ingress) ‚Üí Rate Limiting ‚Üí Walidacja JWT          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  WARSTWA APLIKACJI                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   Device     ‚îÇ  ‚îÇ  Auth/RBAC   ‚îÇ  ‚îÇ   Alerting   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ  ‚îÇ   Service    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  (FastAPI)   ‚îÇ  ‚îÇ  (FastAPI)   ‚îÇ  ‚îÇ  (FastAPI)   ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ             WARSTWA PAMIƒòCI PODRƒòCZNEJ I KOLEJEK            ‚îÇ
‚îÇ  Redis Cluster (Cache + Sesje + Broker Celery)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  WORKERZY KOLEKTOR√ìW                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ   ICMP   ‚îÇ ‚îÇ   SNMP   ‚îÇ ‚îÇ   SSH    ‚îÇ ‚îÇ  Syslog  ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ Collector‚îÇ ‚îÇ Collector‚îÇ ‚îÇ Collector‚îÇ ‚îÇ Collector‚îÇ        ‚îÇ
‚îÇ  ‚îÇ (Celery) ‚îÇ ‚îÇ (Celery) ‚îÇ ‚îÇ (Celery) ‚îÇ ‚îÇ (Celery) ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 WARSTWA DANYCH I SEKRET√ìW                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  PostgreSQL 16  ‚îÇ  ‚îÇ  TimescaleDB    ‚îÇ  ‚îÇ HashiCorp    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Inwentarz)    ‚îÇ  ‚îÇ  (Szeregi czas.)‚îÇ  ‚îÇ Vault        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           WARSTWA OBSERWOWALNO≈öCI (Stos PLT)                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Prometheus     ‚îÇ  ‚îÇ  Loki           ‚îÇ  ‚îÇ Tempo        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (Metryki)      ‚îÇ  ‚îÇ  (Logi)         ‚îÇ  ‚îÇ (≈ölady)      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ           Grafana (Zunifikowany Dashboard)             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Warstwa Wdro≈ºenia (Architektura Infrastruktury)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  STACJA ROBOCZA DEWELOPERA                   ‚îÇ
‚îÇ            (VS Code + DevContainer)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ git push
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Repozytorium GitHub (sotp-backend)              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Potok CI (.github/workflows/ci.yml)                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚úì Lint (Black, isort, ESLint, Prettier)             ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚úì Testy (Pytest >80% pokrycia, Vitest)              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚úì Skanowanie bezp. (Bandit, Safety, Trivy)          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚úì Budowanie obraz√≥w Docker (Multi-stage)            ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Potok CD (.github/workflows/deploy.yml)              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚úì Push obraz√≥w do GHCR                              ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  ‚úì Aktualizacja tag√≥w obraz√≥w w repo sotp-k8s-config ‚îÇ    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            GitHub: sotp-k8s-config (Repozytorium GitOps)     ‚îÇ
‚îÇ  infrastructure/helm/sotp/                                   ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ Chart.yaml                                            ‚îÇ
‚îÇ    ‚îú‚îÄ‚îÄ values.yaml  ‚Üê image.tag aktualizowany przez CD       ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ templates/                                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ ArgoCD obserwuje to repozytorium
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Klaster Kubernetes (K3d lokalnie / Chmura)         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ ArgoCD (Kontroler GitOps)                            ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Wykrywa zmiany w sotp-k8s-config                  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Auto-synchronizacja: helm upgrade sotp ...        ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Sprawdzanie zdrowia i Auto-rollback               ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Linkerd Service Mesh (Opcjonalnie - Faza 5)          ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Automatyczne mTLS miƒôdzy serwisami                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Metryki L7 (success rate, latency)                ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ  - Retries & Circuit breaking                        ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Wdro≈ºona Aplikacja (SOTP):                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ-‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇFastAPI ‚îÇ ‚îÇCelery  ‚îÇ ‚îÇRedis   ‚îÇ ‚îÇPostgreSQL‚îÇ ‚îÇPrometheus‚îÇ  ‚îÇ
‚îÇ  ‚îÇ(3 pody)‚îÇ ‚îÇWorkers ‚îÇ ‚îÇCluster ‚îÇ ‚îÇ  + TS    ‚îÇ ‚îÇ+ Loki +  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ        ‚îÇ ‚îÇ(5 pod) ‚îÇ ‚îÇ        ‚îÇ ‚îÇ          ‚îÇ ‚îÇ  Tempo   ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ-‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Struktura Projektu

```
sotp/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ v1/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devices.py          # CRUD UrzƒÖdze≈Ñ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py             # Autentykacja JWT
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py          # Zapytania do TimescaleDB
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logs.py             # Zapytania do Loki
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerts.py           # ZarzƒÖdzanie alertami
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ commands.py         # Wykonywanie polece≈Ñ SSH
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reports.py          # Generowanie raport√≥w
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ webhooks.py         # Webhooki Alertmanagera
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dependencies.py         # Zale≈ºno≈õci FastAPI
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Ustawienia Pydantic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ security.py             # JWT, hashowanie hase≈Ç
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py             # Konfiguracja SQLAlchemy
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ observability.py        # Konfiguracja OpenTelemetry
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exceptions.py           # W≈Çasne wyjƒÖtki
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ device.py               # Model ORM urzƒÖdzenia
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py                 # Model ORM u≈ºytkownika
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audit_log.py            # ≈ölad audytowy
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alert.py                # Model alertu
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ alert_rule.py           # Konfiguracja regu≈Ç alert√≥w
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ device.py               # Schematy Pydantic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metric.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ alert.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ device_service.py       # Logika biznesowa
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vault_service.py        # Integracja z Vault
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alert_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ remediation_service.py  # Auto-remediacja
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collectors/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # Abstrakcyjny kolektor
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ icmp_collector.py       # Kolektor Ping
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ snmp_collector.py       # Kolektor SNMP
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ssh_collector.py        # Wykonywanie polece≈Ñ SSH
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ syslog_collector.py     # Odbiornik Syslog
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ celery_app.py           # Konfiguracja Celery
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ monitoring_tasks.py     # Zadania pollingu
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alert_tasks.py          # Ewaluacja alert√≥w
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backup_tasks.py         # Backup konfiguracji
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ml_tasks.py             # Predykcje ML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ parsers.py              # Parsery TextFSM
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ validators.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ helpers.py
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_collectors.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_services.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_utils.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_api.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_tasks.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ test_flows.py
‚îÇ   ‚îú‚îÄ‚îÄ alembic/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ env.py                      # Wsparcie dla wielu baz danych
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ versions/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 001_initial_postgres.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 002_initial_timescale.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ requirements-dev.txt
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile                      # Budowanie wieloetapowe
‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml                  # Konfiguracja Poetry/Ruff
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (auth)/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ register/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ (dashboard)/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx            # PrzeglƒÖd
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ devices/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx        # Lista urzƒÖdze≈Ñ
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [id]/page.tsx   # Szczeg√≥≈Çy urzƒÖdzenia
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ [id]/console/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logs/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alerts/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reports/page.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ layout.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/                     # Komponenty shadcn/ui
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ forms/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DeviceForm.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AlertRuleForm.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ charts/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LineChart.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ HeatMap.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tables/
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ DeviceTable.tsx
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useAuth.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ useDevices.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ useMetrics.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts                  # Instancja Axios
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.ts                 # Funkcje pomocnicze autentykacji
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tracing.ts              # OpenTelemetry
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ device.ts
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metric.ts
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îú‚îÄ‚îÄ tsconfig.json
‚îÇ   ‚îú‚îÄ‚îÄ next.config.js
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ infrastructure/
‚îÇ   ‚îú‚îÄ‚îÄ docker/                          # Tylko dla lokalnego DevContainera
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.dev.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init-scripts/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ postgres-init.sql
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ timescale-init.sql
‚îÇ   ‚îú‚îÄ‚îÄ kubernetes/                      # Surowe manifesty K8s (backup)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ helm/                            # PODSTAWOWA metoda wdro≈ºenia
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sotp/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ Chart.yaml
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ values.yaml
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ values-dev.yaml
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ values-prod.yaml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ _helpers.tpl
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ backend-deployment.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ backend-service.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ celery-worker.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ celery-beat.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ frontend-deployment.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ postgres.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ timescale.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ redis.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ vault.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ prometheus.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ loki.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ tempo.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ grafana.yaml
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ ingress.yaml
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ migrations-job.yaml
‚îÇ   ‚îú‚îÄ‚îÄ argocd/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ application.yaml            # Definicja aplikacji ArgoCD
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ project.yaml
‚îÇ   ‚îú‚îÄ‚îÄ prometheus/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rules/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ alerts.yaml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ recording.yaml
‚îÇ   ‚îú‚îÄ‚îÄ grafana/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboards/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ network-overview.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ device-details.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system-health.json
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ observability.json      # Zunifikowany PLT
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ datasources/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ datasources.yaml
‚îÇ   ‚îú‚îÄ‚îÄ loki/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îÇ   ‚îú‚îÄ‚îÄ tempo/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îÇ   ‚îú‚îÄ‚îÄ vault/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ policies/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ backend-policy.hcl
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ k8s-auth.hcl
‚îÇ   ‚îî‚îÄ‚îÄ linkerd/                         # Faza 5
‚îÇ       ‚îî‚îÄ‚îÄ service-profiles/
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ 00-OVERVIEW.md                   # PrzeglƒÖd projektu
‚îÇ   ‚îú‚îÄ‚îÄ 01-REQUIREMENTS.md               # Pe≈Çne wymagania
‚îÇ   ‚îú‚îÄ‚îÄ 02-USER_STORIES.md               # Wszystkie historyjki u≈ºytkownika
‚îÇ   ‚îú‚îÄ‚îÄ 03-ARCHITECTURE.md               # Diagramy C4
‚îÇ   ‚îú‚îÄ‚îÄ 04-API.md                        # Dokumentacja API
‚îÇ   ‚îú‚îÄ‚îÄ 05-DATABASE.md                   # Schemat bazy danych
‚îÇ   ‚îú‚îÄ‚îÄ 06-DEPLOYMENT.md                 # Przewodnik wdro≈ºeniowy
‚îÇ   ‚îú‚îÄ‚îÄ 07-OBSERVABILITY.md              # Przewodnik po stosie PLT
‚îÇ   ‚îú‚îÄ‚îÄ 08-GITOPS.md                     # Przep≈Çyw pracy GitOps
‚îÇ   ‚îú‚îÄ‚îÄ 09-SECURITY.md                   # Praktyki bezpiecze≈Ñstwa
‚îÇ   ‚îú‚îÄ‚îÄ 10-TESTING.md                    # Strategia testowania
‚îÇ   ‚îú‚îÄ‚îÄ 11-DISASTER_RECOVERY.md          # Procedury DR
‚îÇ   ‚îú‚îÄ‚îÄ 12-TROUBLESHOOTING.md            # RozwiƒÖzywanie problem√≥w
‚îÇ   ‚îî‚îÄ‚îÄ 99-ADR/                          # Decyzje architektoniczne
‚îÇ       ‚îú‚îÄ‚îÄ 001-why-kubernetes.md
‚îÇ       ‚îú‚îÄ‚îÄ 002-why-gitops.md
‚îÇ       ‚îî‚îÄ‚îÄ 003-why-service-mesh.md
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh                         # Wstƒôpna konfiguracja
‚îÇ   ‚îú‚îÄ‚îÄ k3d-cluster.sh                   # Tworzenie klastra K3d
‚îÇ   ‚îú‚îÄ‚îÄ install-argocd.sh                # Instalacja ArgoCD
‚îÇ   ‚îú‚îÄ‚îÄ install-linkerd.sh               # Instalacja Linkerd
‚îÇ   ‚îú‚îÄ‚îÄ backup.sh                        # Backup baz danych
‚îÇ   ‚îú‚îÄ‚îÄ restore.sh                       # Odtwarzanie z backupu
‚îÇ   ‚îú‚îÄ‚îÄ seed-demo-data.py                # Dane demonstracyjne
‚îÇ   ‚îî‚îÄ‚îÄ generate-secrets.sh              # Generowanie sekret√≥w
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml                       # Testowanie i Budowanie
‚îÇ       ‚îú‚îÄ‚îÄ deploy-dev.yml               # Wdro≈ºenie na dev
‚îÇ       ‚îú‚îÄ‚îÄ deploy-prod.yml              # Wdro≈ºenie na prod
‚îÇ       ‚îî‚îÄ‚îÄ security-scan.yml            # Cotygodniowe skanowanie bezp.
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ Makefile                             # Polecenia pomocnicze
‚îî‚îÄ‚îÄ README.md
```

---

### Stos Technologiczny

|**Warstwa**|**Technologia**|**Uzasadnienie**|
|---|---|---|
|**Orkiestracja**|K3d (K3s) + Helm|Lekki K8s do lokalnego developmentu. Gotowy na produkcjƒô. Helm standaryzuje wdro≈ºenia.|
|**GitOps**|ArgoCD|Deklaratywne wdro≈ºenia (pull-based CD). Standard bran≈ºowy. Auto-synchronizacja, rollback, wykrywanie dryfu.|
|**Service Mesh**|Linkerd (Faza 5)|Automatyczne mTLS, metryki L7, odporno≈õƒá. L≈ºejszy ni≈º Istio.|
|**Frontend**|Next.js 14 + React + Tailwind|Nowoczesny, szybki, przyjazny SEO. shadcn/ui dla komponent√≥w.|
|**Backend**|FastAPI + Python 3.11+|Asynchroniczne I/O, auto-dokumentacja OpenAPI, walidacja Pydantic, wsparcie OpenTelemetry.|
|**Kolejka Zada≈Ñ**|Celery + Redis|Rozproszone wykonywanie zada≈Ñ. Idealne do odpytywania tysiƒôcy urzƒÖdze≈Ñ.|
|**Bazy Danych**|PostgreSQL 16 + TimescaleDB 2.13|Postgres dla inwentarza, TimescaleDB dla szereg√≥w czasowych. Jeden jƒôzyk zapyta≈Ñ.|
|**Sekrety**|HashiCorp Vault|Dynamiczne sekrety, szyfrowanie jako us≈Çuga, logowanie audytowe. Standard bran≈ºowy.|
|**Obserwowalno≈õƒá**|||
|- Metryki|Prometheus + Alertmanager|De-facto standard. Potƒô≈ºny PromQL. Natywna integracja z K8s.|
|- Logi|Loki + Promtail|"Prometheus dla log√≥w". Niski koszt. Zapytania oparte na etykietach.|
|- ≈ölady|Tempo|Rozproszony tracing. Natywny dla OpenTelemetry. Widoczno≈õƒá pe≈Çnego cyklu ≈ºycia ≈ºƒÖdania.|
|- Wizualizacja|Grafana|Zunifikowany dashboard dla metryk, log√≥w i ≈õlad√≥w. Standard bran≈ºowy.|
|**Kolektory**|icmplib, pysnmp, netmiko, textfsm|Biblioteki Python dla ICMP, SNMP, SSH, parsowania.|
|**CI/CD**|GitHub Actions|Natywna integracja z GitHub. Darmowe dla publicznych repozytori√≥w.|
|**≈örod. Deweloperskie**|VS Code DevContainers|Sp√≥jne ≈õrodowisko deweloperskie. Koniec z "u mnie dzia≈Ça".|
|**ML/AI (Faza 5)**|TimescaleDB Toolkit + Prophet|Wbudowane funkcje ML. Prognozowanie szereg√≥w czasowych.|
|**Load Balancer**|Traefik (K8s Ingress Controller)|Dynamiczna konfiguracja. Automatyczne SSL (Let's Encrypt). Eksport metryk.|

---

### Kompletny Podzia≈Ç na Fazy (Zaktualizowane Role)

**Zesp√≥≈Ç:**

- **Osoba 1 (Lider DevOps):** Odpowiedzialny za platformƒô, infrastrukturƒô (K8s, Helm), CI/CD, GitOps (ArgoCD), stos obserwowalno≈õci (PLT), bezpiecze≈Ñstwo (Vault, Linkerd).
    
- **Osoba 2 (Frontend Developer):** Odpowiedzialny za ca≈Çe UI/UX (Next.js, React, Tailwind).
    
- **Osoba 3 (Specjalista ds. Kolektor√≥w):** Odpowiedzialny za logikƒô zbierania danych (ICMP, SNMP, SSH - `pysnmp`, `netmiko`).
    
- **Osoba 4 (Backend Developer):** Odpowiedzialny za aplikacjƒô (FastAPI), API, logikƒô biznesowƒÖ, modele baz danych (SQLAlchemy), schematy (Pydantic) i definicje zada≈Ñ Celery.
    

#### FAZA 0: Fundamenty i Proof of Concept (1 Tydzie≈Ñ)

**Cel:** Walidacja kluczowych koncepcji przed du≈ºƒÖ inwestycjƒÖ czasowƒÖ.

**0.1 Konfiguracja ≈örodowiska (1 dzie≈Ñ)**

- **Odpowiedzialni:** Wszyscy
    
- **Zadania:** Instalacja narzƒôdzi, inicjalizacja Git, konfiguracja DevContainer.
    
- **Rezultaty:** Dzia≈ÇajƒÖcy DevContainer, `Makefile`, `README.md`.
    
- **Kryteria Sukcesu:** `make setup` dzia≈Ça; wszyscy majƒÖ identyczne ≈õrodowisko.
    

**0.2 POC: Kolektor ICMP + Prometheus + Grafana (2 dni)**

- **Odpowiedzialny:** Osoba 3 (Specjalista ds. Kolektor√≥w)
    
- **Cel:** Udowodnienie, ≈ºe potrafimy zbieraƒá metryki i je wizualizowaƒá (na prostym Docker Compose).
    
- **Zadania:** Skrypt Pythona (`icmplib`), `docker-compose.yml` (Prometheus, Grafana), dashboard.
    
- **Rezultaty:** Dzia≈ÇajƒÖcy skrypt POC, pliki konfiguracyjne, dashboard.
    
- **Kryteria Sukcesu:** Metryki widoczne w Grafanie; dashboard reaguje na zmiany w sieci.
    

**0.3 Definicja Wymaga≈Ñ (2 dni)**

- **Odpowiedzialni:** Wszyscy (sesja warsztatowa)
    
- **Zadania:** Definicja Historyjek U≈ºytkownika (30+), Wymaga≈Ñ Funkcjonalnych i Niefunkcjonalnych, Decyzji Architektonicznych (ADR).
    
- **Rezultaty:** `docs/01-REQUIREMENTS.md`, `docs/02-USER_STORIES.md`, `docs/99-ADR/`.
    
- **Kryteria Sukcesu:** Wymagania zatwierdzone; ADR dokumentujƒÖ kluczowe decyzje.
    

---

#### FAZA 1: MVP - Fundamenty Kubernetes (3-4 Tygodnie)

**Cel:** Dzia≈ÇajƒÖca aplikacja na Kubernetes z podstawowym CRUD i monitoringiem.

**1.1 Konfiguracja Lokalnego Klastra Kubernetes (2 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Skrypt `k3d-cluster.sh`, konfiguracja port√≥w, instalacja `metrics-server`, lokalne repozytorium obraz√≥w.
    
- **Rezultaty:** Skrypt do tworzenia klastra, wpisy w `Makefile`, dokumentacja wdro≈ºenia.
    
- **Kryteria Sukcesu:** Klaster K3d dzia≈Ça; mo≈ºna wysy≈Çaƒá obrazy do lokalnego rejestru.
    

**1.2 Stworzenie Helm Chart (3 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Stworzenie struktury `helm create`, definicja `values.yaml`, stworzenie szablon√≥w dla wszystkich komponent√≥w (backend, frontend, bazy danych, obserwowalno≈õƒá).
    
- **Rezultaty:** Kompletny Helm chart w `infrastructure/helm/sotp/`.
    
- **Kryteria Sukcesu:** `helm lint .` przechodzi; `helm install ...` wdra≈ºa wszystkie pody.
    

**1.3 Schemat Bazy Danych i Migracje (2 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Definicja modeli SQLAlchemy; konfiguracja Alembic dla wielu baz (Postgres + Timescale); stworzenie poczƒÖtkowych migracji.
    
- **Zadanie (Lider DevOps):** Stworzenie K8s Job (`migrations-job.yaml`) w Helm charcie do automatycznego uruchamiania migracji.
    
- **Rezultaty:** `backend/app/models/*.py`, `backend/alembic/versions/*`, `docs/05-DATABASE.md`.
    
- **Kryteria Sukcesu:** Migracje sƒÖ idempotentne; Job uruchamia siƒô poprawnie przed startem aplikacji.
    

**1.4 Implementacja Rdzenia Backend API (4 dni)**

- **Odpowiedzialny:** Osoba 4 (Backend Developer)
    
- **Zadania:** Konfiguracja `main.py` (FastAPI), implementacja endpoint√≥w CRUD dla urzƒÖdze≈Ñ, implementacja warstwy serwisowej (`device_service.py`) z logikƒÖ biznesowƒÖ i walidacjƒÖ.
    
- **Rezultaty:** `backend/app/main.py`, `.../api/v1/devices.py`, `.../services/device_service.py`, `.../schemas/device.py`.
    
- **Kryteria Sukcesu:** Endpointy CRUD dzia≈ÇajƒÖ; walidacja Pydantic dzia≈Ça; dokumentacja OpenAPI jest kompletna.
    

**1.5 Produkcyjna Implementacja Kolektora ICMP (3 dni)**

- **Odpowiedzialny:** Osoba 3 (Specjalista ds. Kolektor√≥w)
    
- **Zadania:** Implementacja logiki `ICMPCollector` (z `icmplib` i `tenacity` for retries).
    
- **Zadanie (Osoba 4):** Definicja zada≈Ñ Celery (`poll_device_icmp`, `poll_all_devices_icmp`) i logiki zapisu do TimescaleDB.
    
- **Rezultaty:** `.../collectors/icmp_collector.py`, `.../tasks/monitoring_tasks.py`.
    
- **Kryteria Sukcesu:** Metryki ICMP sƒÖ poprawnie zbierane i zapisywane w TimescaleDB co 30 sekund.
    

**1.6 Podstawowy Interfejs U≈ºytkownika (Frontend) (5 dni)**

- **Odpowiedzialny:** Osoba 2 (Frontend Developer)
    
- **Zadania:** Konfiguracja Next.js, layout (Sidebar/Navbar), strona listy urzƒÖdze≈Ñ (`DeviceTable.tsx`), formularz (`DeviceForm.tsx`), klient API (`lib/api.ts`).
    
- **Rezultaty:** Dzia≈ÇajƒÖca strona `/devices` pozwalajƒÖca na pe≈Çny CRUD.
    
- **Kryteria Sukcesu:** Mo≈ºna dodawaƒá, edytowaƒá i usuwaƒá urzƒÖdzenia przez UI; stany ≈Çadowania/b≈Çƒôd√≥w sƒÖ obs≈Çu≈ºone.
    

**1.7 Testowanie i Potok CI (3 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps - Potoki) i Wszyscy (Pisanie Test√≥w)
    
- **Zadania:** Pisanie test√≥w jednostkowych i integracyjnych (Backend/Frontend); Stworzenie potoku `ci.yml` (Lint, Test, Build, Scan); Konfiguracja Codecov.
    
- **Rezultaty:** `backend/tests/`, `frontend/tests/`, `.github/workflows/ci.yml`.
    
- **Kryteria Sukcesu:** Pokrycie testami backendu > 80%; Potok CI automatycznie blokuje b≈Çƒôdny kod.
    

---

#### FAZA 2: Bezpiecze≈Ñstwo i Zaawansowany Monitoring (3 Tygodnie)

**Cel:** Zabezpieczenie aplikacji i rozbudowa mo≈ºliwo≈õci zbierania danych.

**2.1 Autentykacja i Autoryzacja (RBAC) (4 dni)**

- **Odpowiedzialny:** Osoba 4 (Backend Developer)
    
- **Zadania:** Implementacja JWT (access/refresh), endpointy `/login`, `/register`, hashowanie hase≈Ç, zale≈ºno≈õci FastAPI do ochrony endpoint√≥w w oparciu o role.
    
- **Zadanie (Osoba 2):** Stworzenie stron logowania/rejestracji, implementacja "Protected Routes" i zarzƒÖdzanie stanem sesji (Zustand).
    
- **Rezultaty:** `.../api/v1/auth.py`, `.../core/security.py`, `frontend/(auth)/login/page.tsx`.
    
- **Kryteria Sukcesu:** Endpointy sƒÖ chronione; przep≈Çyw logowania dzia≈Ça; u≈ºytkownik jest wylogowywany po wyga≈õniƒôciu tokena.
    

**2.2 Pe≈Çna Integracja z HashiCorp Vault (3 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps - Infrastruktura) i Osoba 4 (Backend Developer - Aplikacja)
    
- **Zadania (DevOps):** Wdro≈ºenie Vault i Vault Secrets Injector w K8s; konfiguracja r√≥l i polityk.
    
- **Zadania (Backend):** Stworzenie `VaultService` (`hvac`); modyfikacja `config.py` do pobierania sekret√≥w z Vault przy starcie (zamiast envars).
    
- **Rezultaty:** `.../services/vault_service.py`; adnotacje Vault w `backend-deployment.yaml`.
    
- **Kryteria Sukcesu:** Aplikacja nie przechowuje ≈ºadnych hase≈Ç w `values.yaml`; sekrety sƒÖ wstrzykiwane dynamicznie.
    

**2.3 Implementacja Kolektora SNMP (5 dni)**

- **Odpowiedzialny:** Osoba 3 (Specjalista ds. Kolektor√≥w)
    
- **Zadania:** Implementacja logiki `SNMPCollector` (`pysnmp`) wspierajƒÖcej v2c i v3; pobieranie po≈õwiadcze≈Ñ z Vault.
    
- **Zadanie (Osoba 4):** Definicja zadania `poll_device_snmp(device_id)` i logiki zapisu metryk (CPU, RAM, Interfejsy) do TimescaleDB.
    
- **Rezultaty:** `.../collectors/snmp_collector.py`.
    
- **Kryteria Sukcesu:** Dane SNMPv3 sƒÖ poprawnie zbierane i zapisywane w TimescaleDB.
    

**2.4 Frontend - UI Metryk (4 dni)**

- **Odpowiedzialny:** Osoba 2 (Frontend Developer) i Osoba 4 (Backend Developer)
    
- **Zadania (Backend):** Stworzenie endpointu API `GET /api/v1/devices/{id}/metrics` do pobierania danych z TimescaleDB.
    
- **Zadania (Frontend):** Dodanie zak≈Çadki "Metryki" na stronie urzƒÖdzenia; implementacja wykres√≥w (`recharts`) dla ICMP, CPU, RAM, Ruchu Sieciowego; dodanie wyboru zakresu czasu.
    
- **Rezultaty:** `.../api/v1/metrics.py`; zaktualizowana strona `frontend/devices/[id]/page.tsx`.
    
- **Kryteria Sukcesu:** Wykresy na stronie urzƒÖdzenia pokazujƒÖ dane historyczne i aktualizujƒÖ siƒô po zmianie zakresu czasu.
    

**2.5 Dashboardy Grafana (2 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Wdro≈ºenie Grafany (przez Helm); automatyczny provisioning ≈∫r√≥de≈Ç danych (Prometheus, TimescaleDB); stworzenie dashboard√≥w "as code" (`network-overview.json`, `device-details.json`, `system-health.json`).
    
- **Rezultaty:** `infrastructure/grafana/dashboards/*.json`.
    
- **Kryteria Sukcesu:** Dashboardy sƒÖ automatycznie ≈Çadowane przy starcie Grafany; `device-details.json` poprawnie filtruje dane.
    

---

#### FAZA 3: Obserwowalno≈õƒá i Automatyzacja CD (GitOps) (3 Tygodnie)

**Cel:** OsiƒÖgniƒôcie pe≈Çnej obserwowalno≈õci (stos PLT) i wdro≈ºenie wzorca GitOps.

**3.1 Filar Obserwowalno≈õci 1: Metryki (Prometheus) (2 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Wdro≈ºenie `prometheus-operator`; konfiguracja `ServiceMonitor` do automatycznego scrapowania backendu; wdro≈ºenie `Alertmanager`.
    
- **Rezultaty:** Dzia≈ÇajƒÖcy stos Prometheus + Alertmanager.
    
- **Kryteria Sukcesu:** Metryki API sƒÖ automatycznie zbierane.
    

**3.2 Filar Obserwowalno≈õci 2: Logi (Loki) (3 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Wdro≈ºenie `Loki` i `Promtail`; konfiguracja `Promtail` (DaemonSet) do zbierania log√≥w ze wszystkich pod√≥w w namespace.
    
- **Rezultaty:** Dzia≈ÇajƒÖcy stos Loki; logi widoczne w Grafanie.
    
- **Kryteria Sukcesu:** Mo≈ºna przeszukiwaƒá logi wszystkich pod√≥w z poziomu Grafany.
    

**3.3 Filar Obserwowalno≈õci 3: ≈ölady (Tempo) (4 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps - Infrastruktura) i Osoba 4 (Backend Developer - Aplikacja)
    
- **Zadania (DevOps):** Wdro≈ºenie `Grafana Tempo` (Helm); konfiguracja ≈∫r√≥de≈Ç danych w Grafanie (Tempo + powiƒÖzanie z Loki).
    
- **Zadania (Backend):** Instrumentacja kodu (`opentelemetry-distro`, `...-fastapi`, `...-celery`, `...-sqlalchemy`); konfiguracja `observability.py` do wysy≈Çania ≈õlad√≥w do Tempo.
    
- **Rezultaty:** `.../core/observability.py`; zaktualizowane `requirements.txt`.
    
- **Kryteria Sukcesu:** Mo≈ºna prze≈õledziƒá pe≈Çny cykl ≈ºycia ≈ºƒÖdania (API -> Celery -> Baza Danych) i przej≈õƒá ze ≈õladu do log√≥w.
    

**3.4 Wdro≈ºenie GitOps (ArgoCD) (5 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Stworzenie **drugiego** repozytorium `sotp-k8s-config`; przeniesienie tam Helm charta; instalacja ArgoCD; stworzenie manifestu `Application` ArgoCD.
    
- **Zadanie (Aktualizacja Potoku):** Modyfikacja `deploy-prod.yml`, aby po zbudowaniu obrazu aktualizowa≈Ç `image.tag` w `values.yaml` w repozytorium `sotp-k8s-config`.
    
- **Rezultaty:** Dwa repozytoria; dzia≈ÇajƒÖca instancja ArgoCD; w pe≈Çni zautomatyzowany potok CD (GitOps).
    
- **Kryteria Sukcesu:** `git push` do `sotp-backend` powoduje automatyczne wdro≈ºenie nowej wersji na klastrze przez ArgoCD.
    

---

#### FAZA 4: Funkcjonalno≈õƒá Produkcyjna (3-4 Tygodnie)

**Cel:** Uko≈Ñczenie implementacji funkcji produktu.

**4.1 Kolektor SSH (Netmiko) (5 dni)**

- **Odpowiedzialny:** Osoba 3 (Logika Kolektora) i Osoba 4 (Endpoint API)
    
- **Zadania (Osoba 3):** Implementacja `SSHCollector` (`netmiko`) i parser√≥w `TextFSM`.
    
- **Zadania (Osoba 4):** Stworzenie endpointu API `POST .../execute` (z bia≈ÇƒÖ listƒÖ polece≈Ñ), kolejkowanie przez Celery, zwracanie sparsowanego JSON.
    
- **Zadanie (Osoba 2):** Stworzenie zak≈Çadki "Konsola" w UI.
    
- **Rezultaty:** `.../collectors/ssh_collector.py`, `.../api/v1/commands.py`, `frontend/.../console/page.tsx`.
    
- **Kryteria Sukcesu:** Mo≈ºna wykonaƒá `show version` z UI i zobaczyƒá sparsowany JSON; pr√≥ba wykonania `config t` jest blokowana.
    

**4.2 Kolektor Syslog i Logi Audytowe (4 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps - Syslog) i Osoba 4 (Backend Developer - Audyt)
    
- **Zadania (DevOps):** Konfiguracja Promtail do odbierania Sysloga z urzƒÖdze≈Ñ sieciowych i przesy≈Çania do Loki.
    
- **Zadania (Backend):** Implementacja modelu `AuditLog` (Postgres); stworzenie middleware FastAPI do automatycznego logowania wszystkich ≈ºƒÖda≈Ñ POST/PUT/DELETE.
    
- **Zadanie (Osoba 2):** Stworzenie UI (`/logs`) do przeglƒÖdania log√≥w Syslog (Loki) i Audytowych (Postgres).
    
- **Rezultaty:** Zaktualizowany `promtail/config.yaml`; `.../models/audit_log.py`; `frontend/.../logs/page.tsx`.
    
- **Kryteria Sukcesu:** Logi z routera sƒÖ widoczne w Loki; usuniƒôcie urzƒÖdzenia przez UI tworzy wpis w tabeli `audit_logs`.
    

**4.3 System Raportowania (3 dni)**

- **Odpowiedzialny:** Osoba 4 (Backend Developer) i Osoba 2 (Frontend Developer)
    
- **Zadania (Backend):** Stworzenie API (`.../reports/generate`), logiki agregacji danych z TimescaleDB, generowanie PDF (`WeasyPrint`) lub CSV.
    
- **Zadania (Frontend):** Stworzenie UI (`/reports`) do wyboru typu raportu, zakresu dat i pobierania pliku.
    
- **Rezultaty:** `.../services/report_service.py`; `frontend/.../reports/page.tsx`.
    
- **Kryteria Sukcesu:** Mo≈ºna wygenerowaƒá i pobraƒá raport dostƒôpno≈õci PDF z ostatnich 7 dni.
    

**4.4 Backup i Disaster Recovery (3 dni)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Stworzenie `CronJob` K8s do codziennego backupu baz (`pg_dump`, `ts-dump`) do S3 (np. MinIO); spisanie i przetestowanie procedury odtwarzania.
    
- **Rezultaty:** `templates/backup-job.yaml`; `docs/11-DISASTER_RECOVERY.md`.
    
- **Kryteria Sukcesu:** Backup jest wykonywany automatycznie; procedura odtwarzania jest przetestowana i dzia≈Ça.
    

---

#### FAZA 5: Wizja i Dalszy Rozw√≥j (Ongoing)

**Cel:** Wdro≈ºenie flagowych funkcji, kt√≥re wyr√≥≈ºniajƒÖ projekt.

**5.1 Wdro≈ºenie Service Mesh (Linkerd)**

- **Odpowiedzialny:** Osoba 1 (Lider DevOps)
    
- **Zadania:** Instalacja Linkerd; wstrzykniƒôcie proxy do pod√≥w aplikacji; konfiguracja `ServiceProfile`.
    
- **Rezultat (Flagowy):** Automatyczne mTLS miƒôdzy wszystkimi serwisami; "Golden Metrics" (RPS, latency, success rate) dla ca≈Çego ruchu.
    

**5.2 Automatyzacja w Zamkniƒôtej Pƒôtli (Closed-Loop Automation)**

- **Odpowiedzialni:** Osoba 1 (DevOps), Osoba 4 (Backend), Osoba 3 (Kolektor)
    
- **Zadania:**
    
    1. (DevOps) Konfiguracja Alertmanager, by wysy≈Ça≈Ç webhooki do API.
        
    2. (Backend) Stworzenie endpointu `/api/v1/webhooks/remediate`, kt√≥ry waliduje alert i kolejkuje zadanie Celery.
        
    3. (Kolektor) Implementacja logiki zadania (`tasks.remediate_interface`) u≈ºywajƒÖc Netmiko.
        
- **Rezultat (Flagowy):** System, kt√≥ry nie tylko informuje o problemie, ale sam pr√≥buje go naprawiƒá (np. restartujƒÖc interfejs).
    

**5.3 Anomalia i Predykcja (AI/ML)**

- **Odpowiedzialny:** Osoba 4 (Backend Developer)
    
- **Zadania:** Instalacja `TimescaleDB Toolkit`; stworzenie zadania Celery (`tasks.predict_trends()`) u≈ºywajƒÖcego wbudowanych funkcji (np. `Prophet`) do generowania predykcji i wykrywania anomalii.
    
- **Rezultat (Flagowy):** Przej≈õcie od monitoringu reaktywnego do proaktywnego ("co≈õ siƒô _zaraz_ zepsuje").
    

**5.4 ZarzƒÖdzanie KonfiguracjƒÖ Sieci (GitOps dla Sieci)**

- **Odpowiedzialny:** Osoba 3 (Kolektor) i Osoba 4 (Backend)
    
- **Zadania (Osoba 3):** Implementacja logiki `backup_config()` (u≈ºywajƒÖc Netmiko).
    
- **Zadania (Osoba 4):** Stworzenie zadania Celery, kt√≥re uruchamia logikƒô i zapisuje konfiguracjƒô do repozytorium `sotp-k8s-config`.
    
- **Rezultat (Flagowy):** Mo≈ºliwo≈õƒá wykonania `git diff` na konfiguracji urzƒÖdzenia; alertowanie o "dryfie" konfiguracji.
    

---

### Kluczowe Metryki Sukcesu

|**Metryka**|**Cel**|
|---|---|
|System Uptime|99.5%+|
|Czas Odpowiedzi API|< 200ms (p95)|
|Wska≈∫nik Sukcesu Pollingu|> 99%|
|Wska≈∫nik Fa≈Çszywych Pozytyw√≥w (Alerty)|< 5%|
|Pokrycie Testami (Backend)|> 80%|
|Podatno≈õci Bezpiecze≈Ñstwa|0 Krytycznych, 0 Wysokich|
|Czƒôstotliwo≈õƒá Wdro≈ºe≈Ñ|Codziennie (dziƒôki GitOps)|
|MTTR (Mean Time To Recovery)|< 15 minut (automatyczne rollbacki)|


### Szacowany Timeline

|**Faza**|**Czas**|**Odpowiedzialni G≈Ç√≥wne**|
|---|---|---|
|Faza 0: POC|1 tydzie≈Ñ|Wszyscy|
|Faza 1: MVP & K8s|3-4 tygodnie|Wszyscy (podzia≈Ç: DevOps, Backend, Frontend, Kolektory)|
|Faza 2: Bezpiecze≈Ñstwo i Monitoring|3 tygodnie|Wszyscy (podzia≈Ç j.w.)|
|Faza 3: Obserwowalno≈õƒá & GitOps|3 tygodnie|Lider DevOps (g≈Ç√≥wnie), Backend (instrumentacja)|
|Faza 4: Funkcjonalno≈õƒá Produkcyjna|3-4 tygodnie|Wszyscy (podzia≈Ç j.w.)|
|Faza 5: Wizja (Funkcje Flagowe)|3-4 tygodnie|Wszyscy (podzia≈Ç j.w.)|
|**TOTAL**|**~16-19 tygodni**|**4-osobowy zesp√≥≈Ç**|